{"cells":[{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\n\nfrom scipy.stats import norm, binom, poisson"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["N = 10000\nseed = 0"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# Generate synthetic MOU\nmou = norm.rvs(loc=40, scale=90, size=N)\nmou[mou<0] = np.nan\n\n# Generate synthetic MBOU\nmbou = norm.rvs(loc=600, scale=300, size=N)\nmbou[mbou<0] = 0\n\n# Generate synthetic SOU\nsou = poisson.rvs(mu=0.99, loc=0, size=N)\n\n# Generate synthetic fl_aparelho\nfl_aparelho = binom.rvs(n=1, p=0.4, size=N)\n\n# Generate synthetic fl_4g_plano\nfl_4g_plano = binom.rvs(n=1, p=0.7, size=N)\n\n# Generate synthetic fl_3gplus\nfl_3gplus = binom.rvs(n=1, p=0.8, size=N)\n\n# Join dataset\ndata = {'mou': mou,\n        'mbou': mbou,\n        'sou': sou,\n        'fl_aparelho': fl_aparelho,\n        'fl_4g_plano': fl_4g_plano,\n        'fl_3g_plus': fl_3gplus}\n\ndata = pd.DataFrame(data) # convirtiendolo a pandas dataframe\n\n# Generate Spark DataFrame\ndata = sqlContext.createDataFrame(data)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["data.show()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# Show data types\ndata.printSchema()\n\n# Make simple describe of data\ndesc = data.describe()\ndesc.show()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler, PCA\n\n# First assemble data\nassembler = VectorAssembler(inputCols=['mbou','mou','sou'],\n                            outputCol='features')\nout = assembler.transform(data)\n\n# Do PCA\npca = PCA(k=2,inputCol='features',outputCol='pca')\nmodel = pca.fit(out)\npca_out = model.transform(out)\n\n# Plot PCA\naux = pca_out.select('pca')\naux = aux.map(lambda x: {'pca1':x[0].array.item(0), 'pca2':x[0].array.item(1)})\naux = aux.toDF(schema=['pca1','pca2'])\ndisplay(aux)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["from pyspark.sql.functions import percent_rank, ntile\nfrom pyspark.sql.window import Window\n\nw = Window.partitionBy().orderBy('mou')"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["print w"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["ptiles = data.select('mou', percent_rank().over(w).alias('ptile'))\n\n# un ejemplo de percentil 99:\nptiles.select('mou', 'ptile').where('round(float(ptile), 10)>0.99').show(1)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["np.arange(0, 110, 10)/float(100)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["mou_perc = [] #empty list\n\nran = np.arange(0, 110, 10)/float(100)\n\nfor r in ran:\n  mou_perc.append(ptiles.select('mou', 'ptile').where(\"round(float(ptile), 10)>='\"+str(r)+\"'\").toPandas().ix[0,0]) # .ix[0,0] es el index , el primer elemento de la matriz resultante\n\nperc_10 = pd.DataFrame({'mou':mou_perc,\n                     'ptile': ran})\n"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["perc_10"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["mou_perc4 = [] #empty list\n\nran4 = np.arange(0, 110, 25)/float(100)\n\nfor r in ran4:\n  mou_perc4.append(ptiles.select('mou', 'ptile').where(\"round(float(ptile), 10)>='\"+str(r)+\"'\").toPandas().ix[0,0]) \n  # .ix[0,0] es el index , el primer elemento de la matriz resultante\n\nquartiles = pd.DataFrame({'mou':mou_perc4,\n                         'ptile': ran4})\n\nquartiles"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# función de Daniel.\n\nimport pandas as pd\nimport numpy as np\n\ndef get_ntiles(df, n=4, cols=None):\n    \n    ntiles = {}\n    ran = map(lambda x: str(x)+'%',np.arange(1,n+1)/float(n)*100)\n    \n    if cols is None:\n        cols = df.columns\n    \n    for c in cols:\n        w = Window.partitionBy().orderBy(c)\n        aux = df.select(ntile(n).over(w).alias('ntile'),c)\n        ntiles.update({c:aux.groupby('ntile').max(c).toPandas().ix[:,1]})\n    \n    ntiles = pd.DataFrame(ntiles)\n    ntiles[str(n)+'-tile'] = ran\n    ntiles.set_index(str(n)+'-tile',inplace=True)\n    #ntiles = ntiles.round(3)\n    return ntiles"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["get_ntiles(data, 20, cols=['mou'])"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nimport numpy as np\n\ndata_pd = data.toPandas()\nfig,ax = plt.subplots()\nax = plt.boxplot(data_pd['mbou'])\nplt.ylim((-500,2000))\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["data_to_plot = [data_pd['mou'], data_pd['mbou']]\n\nfig, ax = plt.subplots()\n\nbp = plt.boxplot(data_to_plot, widths = 0.6)\n\nfor whisker in bp['whiskers']:\n  whisker.set(color='#7570b3', linewidth=2)\n  \nfor flier in bp['fliers']:\n  flier.set(marker='o', color='#e7298a', alpha=0.5)\n  \nplt.ylim((-500, 2500))\n\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":17}],"metadata":{"name":"eda_template","notebookId":306540555204576},"nbformat":4,"nbformat_minor":0}
