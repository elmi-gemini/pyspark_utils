{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Spark import\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import HiveContext\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "conf = SparkConf() \\\n",
    "    .setAppName('pruebas') \\\n",
    "    .setMaster('yarn-client') \\\n",
    "    .set(\"spark.executor.memory\", \"4g\") \\\n",
    "    .set(\"spark.executor.cores\", \"4\") \\\n",
    "    .set(\"spark.executor.instances\", \"2\") \\\n",
    "    .set(\"spark.driver.memory\", \"4g\") \\\n",
    "    .set(\"spark.driver.cores\", \"2\") \\\n",
    "    .set(\"spark.yarn.am.cores\", '4') \\\n",
    "    .set(\"spark.yarn.am.memory\", '8g') \\\n",
    "    .set(\"spark.logConf\", \"false\") \\\n",
    "    .set(\"spark.kryoserializer.buffer.max\", \"2000MB\") \\\n",
    "    .set(\"spark.app.id\", \"myapp\") \\\n",
    "    .set(\"spark.ui.port\", \"4235\") \\\n",
    "    .set(\"spark.yarn.queue\", \"gbic\") \\\n",
    "    .set(\"spark.driver.maxResultSize\",\"2048MB\")    \n",
    "\n",
    "#if sc:\n",
    " #   sc.stop()\n",
    "\n",
    "sc = SparkContext(conf = conf)\n",
    "sqlContext = HiveContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand, randn\n",
    "\n",
    "# Create a DataFrame with one int column and 10 rows.\n",
    "df = sqlContext.range(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+--------------------+\n",
      "| id|            uniform|              normal|\n",
      "+---+-------------------+--------------------+\n",
      "|  0|0.41371264720975787|  0.5888539012978773|\n",
      "|  1| 0.1982919638208397| 0.06157382353970104|\n",
      "|  2|0.12030715258495939|  1.0854146699817222|\n",
      "|  3|0.44292918521277047| -0.4798519469521663|\n",
      "|  4| 0.8898784253886249| -0.8820294772950535|\n",
      "|  5| 0.2731073068483362|-0.15116027592854422|\n",
      "|  6|   0.87079354700073|-0.27674189870783683|\n",
      "|  7|0.27149331793166864|-0.18575112254167045|\n",
      "|  8| 0.6037143578435027|   0.734722467897308|\n",
      "|  9| 0.1435668838975337|-0.30123700668427145|\n",
      "+---+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate two other columns using uniform distribution and normal distribution.\n",
    "\n",
    "#df.select(\"id\", rand(seed=10).alias(\"uniform\"), randn(seed=27).alias(\"normal\")).show()\n",
    "df = df.withColumn('uniform', rand(seed=10))\n",
    "df = df.withColumn('normal', randn(seed=27))\n",
    "\n",
    "df.cache()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a total sum of a column \n",
    "from pyspark.sql.functions import mean, min, max, sum\n",
    "\n",
    "fff = df.select([sum('id')])\n",
    "fff.head()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(sum(id)=45)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fff.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
